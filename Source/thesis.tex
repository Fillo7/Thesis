% !TeX spellcheck = en_US

\documentclass
[
    digital, %% digital / printed
    oneside, %% oneside / twoside
    table, %% table / notable - coloring of tables
    nolof, %% lof / nolof - list of figures inclusion
    nolot, %% lot / nolot - list of tables inclusion
    nocover %% cover / nocover - cover page inclusion
    %% More options at <http://mirrors.ctan.org/macros/latex/contrib/fithesis/guide/mu/fi.pdf>
]{fithesis3}

\usepackage[resetfonts]{cmap}
\usepackage[T1]{fontenc}
\usepackage[main=english, slovak, czech]{babel}

\thesissetup
{
    date = \the\year/\the\month/\the\day,
    university = mu,
    faculty = fi,
    type = mgr,
    author = Bc. Filip Petrovič,
    gender = m,
    advisor = {RNDr. Jiří Filipovič, Ph.D.},
    title = {Framework for Parallel Kernels Autotuning},
    TeXtitle = {Framework for Parallel Kernels Autotuning},
    keywords = {autotuning, GPU programming, OpenCL, CUDA, kernel, optimization},
    TeXkeywords = {autotuning, GPU programming, OpenCL, CUDA, kernel, optimization},
    assignment = {}
}

\thesislong{abstract}
{
    The result of this thesis is a framework for autotuning of parallel kernels which are written in either OpenCL or CUDA language. The framework
    includes advanced functionality such as support for composite kernels and online autotuning. The thesis describes API and internal structure of
    the framework and presents several examples of its utilization for kernel optimization.
}

\thesislong{thanks}
{
    I would like to thank my supervisor Jiří Filipovič for his help and valuable advice. I would also like to thank my family for their support during
    my work on the thesis.
}

%% Insert bibliography
\usepackage{csquotes}
\usepackage
[
    backend=biber,
    style=numeric,
    citestyle=numeric-comp,
    sorting=none,
    sortlocale=auto,
    language=australian
    %% More information at <http://mirrors.ctan.org/macros/latex/contrib/biblatex/doc/biblatex.pdf>
]{biblatex}
\addbibresource{references.bib}
\nocite{*}

%% Insert additional packages
\usepackage{makeidx}
\makeindex
\usepackage{amsbsy}
\usepackage{paralist}
\usepackage{menukeys}
\usepackage{float}

%% Allow extra table formatting commands
\usepackage{array}
\usepackage{ragged2e}
\newcolumntype{L}[1]{>{\RaggedRight\hspace{0pt}}p{#1}}
\newcolumntype{R}[1]{>{\RaggedLeft\hspace{0pt}}p{#1}}

%% Enable inclusion of code samples with coloring
\usepackage{listings}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset
{
    frame=tb,
    language=C,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    columns=flexible,
    basicstyle={\small\ttfamily},
    numbers=none,
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{dkgreen},
    stringstyle=\color{mauve},
    breaklines=true,
    breakatwhitespace=true,
    tabsize=3
}

%% Equations and figures use same numbering
\makeatletter
\let\c@equation\c@figure
\makeatother

%% Make "thanks" section show on top of a page
\makeatletter\thesis@load
\makeatletter
    \def\thesis@blocks@thanks{%
    \ifx\thesis@thanks\undefined\else
    \thesis@blocks@clear
    \begin{alwayssingle}%
    \chapter*{\thesis@@{thanksTitle}}%
    \thesis@thanks
    \end{alwayssingle}%
    \fi}
\makeatother

\begin{document}
\chapter{Introduction}
In recent years, acceleration of complex computations using multi-core processors, graphics cards and other massively parallel devices has become
much more common. Currently, there are many devices developed by multiple vendors which differ in hardware architecture, performance and other
attributes. In order to ensure portability of code written for particular device, several software APIs (application programming interfaces) such as
OpenCL (Open Computing Language) or CUDA (Compute Unified Device Architecture) were designed. Code written in these APIs can be run on various
devices, while always producing the same result. However, there is a problem with portability of performance. For example, code which was optimized
for a GPU may run poorly on a regular multi-core processor. The problem also exists among multiple generations of devices developed by the same
vendor, even if they have comparable parameters and theoretical performance.

A costly solution to this problem is to manually optimize code for each utilized device. This has several significant disadvantages, such as
a necessity to dedicate large amount of resources to write different versions of code and test which one performs best on a given device. Furthermore,
new devices are released frequently and in order to efficiently utilize their capabilities, it is often necessary to rewrite old versions of code and
repeat the optimization process again.

An alternative solution is a technique called autotuning, where code includes parameters which affect performance depending on their value, for
example a parameter which affects length of a vector type of a particular variable. Optimal values of these parameters might differ for various
devices based on their hardware capabilities. Parametrized code is then launched repeatedly using different combinations of parameters to find out the
best configuration for a particular device.

In order to make autotuning easier to implement in applications, several frameworks were created. However, large number of these are focused
only on a very small subset of computations. There are some frameworks which are more general, but their features are limited and only support
simple usage scenarios. The aim of this thesis was to develop autotuning framework which would support more complex use cases, such as situations
where computation is split into several smaller programs. Additionally, the framework should be written in a way which would allow its easy
integration into existing software stacks and possibly combine autotuning with regular computation.

The thesis is split into four main chapters. <Todo: add short description of each chapter.>

\chapter{Compute APIs and autotuning}
This chapter serves as an introduction to autotuning technique and includes description of compute APIs which are utilized by KTT (Kernel Tuning
Toolkit)\footnote{Name of the autotuning framework developed as a part of the thesis.} - OpenCL and CUDA. Because both APIs provide relatively similar
functionality, only OpenCL is described here in greater detail. Section about CUDA is mostly focused on explaining features which differ from OpenCL.
It is worth mentioning that CUDA actually consists of two different APIs - high-level runtime API and low-level driver API. For the purpose of this
thesis, only CUDA driver API will be further described, because the runtime API lacks features which are necessary to implement autotuning in CUDA.

\section{OpenCL}
OpenCL is an API for developing primarily parallel applications which can be run on a range of different devices such as CPUs, GPUs and FPGAs
(field-programmable gate arrays). An OpenCL application consists of two main parts. First part is a host program, which is typically executed on a CPU
and is responsible for OpenCL device configuration, memory management and kernel execution. Second part is a kernel, which is a function executed on
an OpenCL device and usually contains major part of a computation. Kernels are written in OpenCL C which is a language based on C programming
language.

\subsection{Host program in OpenCL}
Host program is written in regular programming language, typically in C or C++. Its main objective is to successfully launch a kernel function. OpenCL
API defines several important structures which are referenced from host program:
\begin{itemize}
    \item cl\_context - serves as a holder of resources, similar to OS process, majority of other OpenCL structures have to be initialized inside a
    specific context
    \item cl\_command\_queue - all commands which are executed directly on OpenCL device have to be submitted inside a command queue, it is possible
    to initialize multiple command queues within a single context in order to overlap independent asynchronous operations
    \item cl\_buffer - todo...
    \item cl\_kernel - todo...
    \item cl\_program - todo...
    \item cl\_event - todo...
\end{itemize}

Execution of an entire OpenCL application then typically consists of the following steps:
\begin{itemize}
    \item selection of target platform (eg. AMD, Intel, Nvidia) and device (eg. GeForce GTX 970)
    \item initialization of OpenCL context and one or more command queues
    \item initialization of OpenCL buffers (either in host or dedicated device memory)
    \item compilation and execution of kernel function
    \item transfer of data produced by kernel from OpenCL buffers into host memory (if data is located in dedicated device memory)
\end{itemize}




\subsection{Kernel in OpenCL}
Todo...

\section{CUDA, comparison with OpenCL}
Todo...

\section{Autotuning in compute APIs}
Todo...

\chapter{Conclusion}
Todo...

%% Print full bibliography, use biber.exe on .bcf file to generate bibliography
{\csname captions\languagename\endcsname
\makeatletter
\thesis@selectLocale{\thesis@locale}\makeatother
\printbibliography[heading=bibintoc]}

\appendix
\chapter{Appendix}
Todo...

\end{document}
